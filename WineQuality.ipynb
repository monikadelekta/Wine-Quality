{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC #support vector classification\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1596 entries, 0 to 1595\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1596 non-null float64\n",
      "volatile acidity        1596 non-null float64\n",
      "citric acid             1596 non-null float64\n",
      "residual sugar          1596 non-null float64\n",
      "chlorides               1596 non-null float64\n",
      "free sulfur dioxide     1596 non-null float64\n",
      "total sulfur dioxide    1596 non-null float64\n",
      "density                 1596 non-null float64\n",
      "pH                      1596 non-null float64\n",
      "sulphates               1596 non-null float64\n",
      "alcohol                 1596 non-null float64\n",
      "quality                 1596 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 149.7 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process data\n",
    "bins = (2, 6.5, 8) #2 bins\n",
    "group_names = ['bad', 'good']\n",
    "\n",
    "#cut means we cut out wine quality and replace it \n",
    "wine['quality'] = pd.cut(wine['quality'], bins = bins, labels = group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bad, good]\n",
       "Categories (2, object): [bad < good]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_quality = LabelEncoder() # sklearn import \n",
    "#fit_transform - calcs means and fits in missing values\n",
    "wine['quality'] = label_quality.fit_transform(wine['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "5            7.4              0.66         0.00             1.8      0.075   \n",
       "6            7.9              0.60         0.06             1.6      0.069   \n",
       "7            7.3              0.65         0.00             1.2      0.065   \n",
       "8            7.8              0.58         0.02             2.0      0.073   \n",
       "9            7.5              0.50         0.36             6.1      0.071   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                 17.0                 102.0   0.9978  3.35       0.80   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        0  \n",
       "1      9.8        0  \n",
       "2      9.8        0  \n",
       "3      9.8        0  \n",
       "4      9.4        0  \n",
       "5      9.4        0  \n",
       "6      9.4        0  \n",
       "7     10.0        1  \n",
       "8      9.5        1  \n",
       "9     10.5        0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1379\n",
       "1     217\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11e8c9450>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(wine['quality']) #seaborn sits on matplotlib with extrea features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate dataset as response variable and feature variables\n",
    "X = wine.drop('quality', axis = 1)\n",
    "y = wine['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test data split - 20% with random selection\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply standard scaling to get optimised result\n",
    "#level playing field for all variables\n",
    "sc = StandardScaler()\n",
    "\n",
    "#apply to train and test\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2684328 , -1.15992969, -0.11655257, -0.17133997, -0.34841935,\n",
       "         0.68159604,  0.33265733, -0.21047789,  0.70530984,  1.86378152,\n",
       "         0.16814376],\n",
       "       [ 0.16241717, -1.10356109,  0.65696208,  0.04451963, -0.10216977,\n",
       "         0.00360553,  0.63314632,  0.57843659, -0.07014103, -1.07728849,\n",
       "        -0.9625621 ],\n",
       "       [ 1.82220314, -1.18811399,  1.37890909, -0.31524637, -0.08164897,\n",
       "        -1.06180814, -0.95944535,  1.04437265, -2.13801003,  0.24319193,\n",
       "        -1.15101307],\n",
       "       [ 1.87943714, -0.28621642,  0.65696208, -0.81891878,  0.06199661,\n",
       "        -0.96495235, -0.56880965,  0.1654478 , -1.55642187, -0.05691726,\n",
       "        -0.36580068],\n",
       "       [ 0.33411917, -0.25803212,  1.32734145,  1.05186445,  0.26720459,\n",
       "        -1.25551972, -1.10968984, -0.4593301 , -0.65172919, -0.41704828,\n",
       "         1.58152608]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many trees per forest - start high \n",
    "rf = RandomForestClassifier(n_estimators = 200) \n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rf[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       277\n",
      "           1       0.70      0.33      0.44        43\n",
      "\n",
      "    accuracy                           0.89       320\n",
      "   macro avg       0.80      0.65      0.69       320\n",
      "weighted avg       0.88      0.89      0.87       320\n",
      "\n",
      "[[271   6]\n",
      " [ 29  14]]\n"
     ]
    }
   ],
   "source": [
    "#check model performance\n",
    "print(classification_report(y_test, pred_rf))\n",
    "print(confusion_matrix(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94       277\n",
      "           1       0.73      0.26      0.38        43\n",
      "\n",
      "    accuracy                           0.89       320\n",
      "   macro avg       0.81      0.62      0.66       320\n",
      "weighted avg       0.87      0.89      0.86       320\n",
      "\n",
      "[[273   4]\n",
      " [ 32  11]]\n"
     ]
    }
   ],
   "source": [
    "#check model performance\n",
    "print(classification_report(y_test, pred_clf))\n",
    "print(confusion_matrix(y_test, pred_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it seems the SVM classifier is performing slightly better than the Random Forest model. \n",
    "\n",
    "SVM works better on smaller numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#multi layered perceptron classifier\n",
    "# hidden layers, 3 layers of 11 each - 11 features coming in, 3 hidden layers\n",
    "# max iterations default is 200, the more layers the more iterations needed \n",
    "mlpc = MLPClassifier(hidden_layer_sizes = (11, 11, 11), max_iter = 600)\n",
    "mlpc.fit(X_train, y_train)\n",
    "pred_mlpc = mlpc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       277\n",
      "           1       0.68      0.53      0.60        43\n",
      "\n",
      "    accuracy                           0.90       320\n",
      "   macro avg       0.80      0.75      0.77       320\n",
      "weighted avg       0.90      0.90      0.90       320\n",
      "\n",
      "[[266  11]\n",
      " [ 20  23]]\n"
     ]
    }
   ],
   "source": [
    "#check model performance\n",
    "print(classification_report(y_test, pred_mlpc))\n",
    "print(confusion_matrix(y_test, pred_mlpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.890625"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best performing model accuracy\n",
    "#random forest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = accuracy_score(y_test, pred_rf)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
